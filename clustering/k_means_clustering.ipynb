{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "Iteratively clusters a data set into K clusters based on the mean of each data point in each centroid.\n",
    "\n",
    "# K-Means Algorithm\n",
    "- Step 1: Choose the number of K clusters\n",
    "- Step 2: Select at random K points\n",
    "    - These points will be the centroids of your clusters\n",
    "    - These centroids don't have to be apart of the data set\n",
    "- Step 3: Assign each data point to the closest centroid\n",
    "    - This step creates K clusters\n",
    "    - Use the Euclidean Distance (distance formula) to determine closest centroid\n",
    "- Step 4: Compute and place the new centroid of each cluster\n",
    "- Step 5: Reassign each data point to the closest centroid\n",
    "    - If any reassignment took place, go to Step 4\n",
    "    - If no reassignment took place, your model is ready\n",
    "\n",
    "### K-Means Algorithm Visualization\n",
    "#### Here's the data set:\n",
    "<img src=\"images/kmc/choose_k_k_means_example.png\" height=\"35%\" width=\"35%\"></img>\n",
    "\n",
    "#### We choose the number of K clusters as K = 2\n",
    "<img src=\"images/kmc/first_iteration_k_means_example.png\" height=\"35%\" width=\"35%\"></img>\n",
    "- First iteration\n",
    "\n",
    "As seen above, two centroids were randomly created because K = 2.  \n",
    "Then, the closest data points to those centroids were assigned.\n",
    "\n",
    "#### Determine new centroid of each cluster, re-assign each data point\n",
    "We need to find the \"center of gravity\" of each cluster, and this \"center of gravity\" is where each centroid will be placed.\n",
    "\n",
    "The following diagram shows the new centroid positions and the re-assignment of the data points:\n",
    "\n",
    "<img src=\"images/kmc/new_centroid_1_k_means_example.png\" height=\"35%\" width=\"35%\"></img>\n",
    "- Second iteration\n",
    "\n",
    "#### Repeat process of determining centroids\n",
    "Keep repeating the centroid placement process until there is no reassignment of data points.\n",
    "\n",
    "#### Model is ready\n",
    "After iterating (repeating) centroid placements, we determined a model where no new reassignment took place when we last placed the centroids. This model became the final model for the data set.\n",
    "\n",
    "<img src=\"images/kmc/ready_model_k_means_example.png\" height=\"35%\" width=\"35%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Random Initialization Trap\n",
    "Sometimes, based on where the initial centroids were placed, it can really determine the outcome of clusters.\n",
    "\n",
    "For instance, in the same data set, based on the placement of the initial clusters these two different results were created.\n",
    "\n",
    "#### K-Means result 1\n",
    "<img src=\"images/kmc/true_cluster_k_means_example.png\" height=\"35%\" width=\"35%\"></img>\n",
    "- The diagram above is the more correct clustering of the data set\n",
    "\n",
    "####  K-Means result 2\n",
    "<img src=\"images/kmc/false_cluster_k_means_example.png\" height=\"35%\" width=\"35%\"></img>\n",
    "- The diagram above is the less correct clustering of the data set\n",
    "\n",
    "### How To Prevent Trap!\n",
    "There is a solution, which is called the K-Means++ that allows the program to correctly select the initial centroids.\n",
    "\n",
    "As it turns out, good initial centroids are ones that aren't close to each other. The K-Means++ algorithm selects initial means that aren't close to each other, then uses the standard K-Means algorithm for clustering.\n",
    "- https://msdn.microsoft.com/en-us/magazine/mt185575.aspx\n",
    "\n",
    "Fortunately, SKLearn implements the K-Means++ algorithm as a default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing The Best Number of K Clusters\n",
    "There's an algorithm to find the best number of K clusters for a data set.\n",
    "- We need to evaluate how a K-value cluster performs compared to another K-value clusters\n",
    "\n",
    "The \"Within Clusters Sum of Squares\" (WCSS) is a metric used to sum of the distance of each point then squaring that distance within each cluster. Then you add-up all the sum of squares.\n",
    "\n",
    "### WCSS for K = 1 Example\n",
    "<img src=\"images/kmc/wcss_k_3.png\" height=\"75%\" width=\"75%\"></img>\n",
    "- \"Pi in Cluster 1\" refers to each point within Cluster 1\n",
    "\n",
    "As seen, the squared distance of each point to the centroid is very far.\n",
    "- In fact, this would create the largest WCSS value\n",
    "\n",
    "### WCSS For K = 3 Example\n",
    "<img src=\"images/kmc/wcss_k_3.png\" height=\"75%\" width=\"75%\"></img>\n",
    "- \"Pi in Cluster 1\" refers to each point within Cluster 1\n",
    "- \"Pi in Cluster 2\" refers to each point within Cluster 2\n",
    "- \"Pi in Cluster 3\" refers to each point within Cluster 3\n",
    "\n",
    "As seen, the squared distance of each point to the centroid is shorter than when K = 1.  \n",
    "- The WCSS value would be less than when K = 1\n",
    "\n",
    "### The Elbow Method\n",
    "How do we find the optimal goodness of K?\n",
    "\n",
    "If we graph WCSS versus Number of Clusters:\n",
    "\n",
    "<img src=\"images/kmc/wcss_graph.png\" height=\"75%\" width=\"75%\"></img>\n",
    "- K = 3 is the optimal number of clusters\n",
    "\n",
    "The optimal number of clusters is the point in the graph in-between huge and small changes of the WCSS-value.\n",
    "- This point is referred to the \"elbow\" point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
