{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Perceptron\n",
    "Let's create an Artificial Neural Network by scratch using only numpy, specifically we'll program a Perceptron. This lecture was created from \"Polycode\" in his video \"Create a Simple Neural Network in Python from Scratch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Set\n",
    "<img src=\"images/sp/problem_set.png\" height=\"65%\" width=\"65%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "<img src=\"images/sp/perceptron.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "We're going to program a perceptron (no hidden layers) to solve this deep learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation (Normalization) Function\n",
    "<img src=\"images/sp/sigmoid.png\" height=\"65%\" width=\"65%\"></img\n",
    "\n",
    "We're going to use the sigmoid activation function to normalize the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the independent variables for training\n",
    "x_train = np.array([\n",
    "    [0, 0, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1]\n",
    "])\n",
    "\n",
    "# the dependent variables for training\n",
    "y_train = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16595599],\n",
       "       [ 0.44064899],\n",
       "       [-0.99977125]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the randomization seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# because we have 3 inputs (columns) and 1 output, initialize a 3x1 matrix with values close to 0\n",
    "synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "synaptic_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of sigmoid activation function\n",
    "def sigmoid_derivative(x):\n",
    "    return np.exp(x) / np.square((1 + np.exp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "for epoch in range(epochs):\n",
    "    # y_pred is the sigmoid multiplication of the training set and synaptic weights\n",
    "    y_pred = sigmoid(np.dot(x_train, synaptic_weights))\n",
    "\n",
    "    # receive the error by subtracting the actual from the predicted values of the training set\n",
    "    error = y_train - y_pred\n",
    "    \n",
    "    \"\"\"\n",
    "    implement gradient descent: weight adjustments equal to error times\n",
    "    sigmoid derivative because we used the sigmoid function as the cost function\n",
    "    to determine the difference (error) of the actual and predicted values.\n",
    "    \"\"\"\n",
    "    adjustments = error * sigmoid_derivative(y_pred)\n",
    "    \n",
    "    # sum the new weights of the synapses with the multiplication of training set and adjustments\n",
    "    synaptic_weights += np.dot(x_train.T, adjustments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synaptic Weights:\n",
      "[[14.48501619]\n",
      " [14.48501743]\n",
      " [-6.90407232]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Synaptic Weights:\")\n",
    "print(synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Training Set:\n",
      "[[0.00100273]\n",
      " [1.        ]\n",
      " [0.99949015]\n",
      " [0.99949016]]\n",
      "\n",
      "Actual Training Set:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# predicted values after fitting the training set\n",
    "print(\"Predicted Training Set:\")\n",
    "print(y_pred)\n",
    "print()\n",
    "\n",
    "# actual values of the training set\n",
    "print(\"Actual Training Set:\")\n",
    "print(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
