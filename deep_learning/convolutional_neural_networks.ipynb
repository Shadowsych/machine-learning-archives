{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Our brain classifies visuals by looking at the features of the object, which is why optical illusions occur. Convolutional Neural Networks are a type of neural network that filter the features of a sample, typically an image, and classify the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "In a convolutional operation, there are 3 components:\n",
    "- Input\n",
    "- Feature Detector (also called Filter or Kernel)\n",
    "- Feature Map (also called a Convolved Feature or Activation Map)\n",
    "\n",
    "The feature detector is a matrix that the convolutional operation uses to detect a feature on the input. Some examples of a feature could be a long nose, green eyes, long eyelashes, etc. that you could create a matrix from and use it to detect on the input.\n",
    "\n",
    "### Example of Convolutional Operation\n",
    "Let's say we gray-scale an image of a smiley face, we can represent it as a 2D matrix below.\n",
    "\n",
    "<img src=\"images/cnn/smiley_example.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "Now we can use a 3x3 (standard size) feature detector to match the cells of the Input.\n",
    "\n",
    "So how do we use the feature detector? If a section of cells in the input matrix match the feature detector, then put the number of matching cells in the feature map. Then go to the next stride (step) to the next section of cells in the matrix. Keep continuing the strides until the feature map is filled.\n",
    "\n",
    "Let's fill the feature map below!\n",
    "\n",
    "<hr>\n",
    "\n",
    "<img src=\"images/cnn/convolutional_operation_1.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "None of the cells in the 3x3 matrix in the image and the feature detector did not match, so place a 0. Let's continue with the next stride.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<img src=\"images/cnn/convolutional_operation_2.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "Only the middle-left cell of the image matched the middle-left cell of the feature detector, so place a 1. Keep continuing the strides until the feature map is filled.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<img src=\"images/cnn/convolutional_operation_3.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "The feature map is smaller than the image, which will be more efficient for the neural network because we only care about this certain feature and not the entire input.\n",
    "\n",
    "### Convolutional Layer\n",
    "<img src=\"images/cnn/convolutional_layer.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "We create many feature maps to create the convolutional layer, which detects all of the features on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU Layer\n",
    "The ReLU layer is the Rectifier Activation Function. It decreases the linearity of the neural network, which helps with seeing abrupt changes in the image.\n",
    "\n",
    "<img src=\"images/cnn/relu_layer.png\" height=\"65%\" width=\"65%\"></img>\n",
    "\n",
    "### Example of ReLU Layer\n",
    "<img src=\"images/cnn/fergus.png\" height=\"40%\" width=\"40%\"></img>\n",
    "\n",
    "This is the original image.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<img src=\"images/cnn/edge_fergus.png\" height=\"40%\" width=\"40%\"></img>\n",
    "\n",
    "This is the original image applied with an edge detector, a type of feature detector that detects edges on an image.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<img src=\"images/cnn/relu_fergus.png\" height=\"40%\" width=\"40%\"></img>\n",
    "\n",
    "This is the edge-detected image with the applied ReLU layer. The abrupt changes in the image are seen with the ReLU layer because the black lines are zeroed out and only the white lines appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
