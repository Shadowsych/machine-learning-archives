{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading The Data Set\n",
    "Before we begin pre-processing the data set, we must load it.\n",
    "- The data set we'll be using is the customers.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the customers csv as a data set\n",
    "customers_df = pd.read_csv(\"datasets/customers.csv\")\n",
    "\n",
    "customers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a 2D Array excluding the last column\n",
    "x = customers_df.iloc[:, :-1].values\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return an Array of the last column\n",
    "y = customers_df.iloc[:, 3].values\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is \"x\"?\n",
    "The x (independent variable) is a 2D Array of the Country, Age, and Salary columns.\n",
    "- Each column is an independent variable\n",
    "- Each row is a sample\n",
    "\n",
    "### What is \"y\"?\n",
    "The y (dependent variable) is an Array of the Purchased column.\n",
    "\n",
    "### So What's The Machine Learning (ML) Problem?\n",
    "The Purchased column is dependent on the Country, Age, and Salary.\n",
    "\n",
    "Therefore, can we can make predictions on whether a customer will purchase an item based on their country, age, and salary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data\n",
    "The customers data set contains some \"NaN\" or undefined cells, so we must handle the missing data before we begin creating machine learning models.\n",
    "\n",
    "### There are multiple ways to fix missing data:\n",
    "1. Remove the columns with missing data (not recommended, dangerous)  \n",
    "2. Set the cell's data to the mean of the columns (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn's SimpleImputer, a class that handles missing data\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an Imputer that replaces NaN cells with its column's mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "\n",
    "# impute, then transform the age (col 1) and salary (col 2) columns\n",
    "x[:, 1:3] = imputer.fit_transform(x[:, 1:3])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit\n",
    "The fit part is used to analyse the data on which we apply the object (getting the mean, the min, the max, the standard deviation, outliers, etc.) in order to understand how the data is structured.\n",
    "\n",
    "### Transform\n",
    "Then once the object understands how the data is structured thanks to the fit method, the transform part is used to apply some transformation (like feature scaling for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data\n",
    "The \"Country\" and \"Purchased\" columns are categorial variables.\n",
    "- The Country column contains 3 categories: France, Spain, Germany\n",
    "- The Purchased column contains 2 categories: Yes, No\n",
    "\n",
    "They are considered \"categorical\" because they simply contain categories.\n",
    "\n",
    "### The Problem with Categorical Variables\n",
    "In Machine Learning, having categorial variables may scew the model because the values could be non-numeric or non-processable.\n",
    "\n",
    "A solution is to encode categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a LabelEncoder\n",
    "labelencoder_x = LabelEncoder()\n",
    "\n",
    "# set each country to its encoded value in the Country column\n",
    "x[:, 0] = labelencoder_x.fit_transform(x[:, 0])\n",
    "\n",
    "# looking at the output, it's either 0, 1, or 2 based on country\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem with The \"Country\" Column's Encoding\n",
    "If we implemented a machine learning model using the country encodings of 0, 1, or 2, then it would think the country with an encoding of 2 has a greater value than the countries of an encoding of 1 and 0.\n",
    "\n",
    "This is not the case since the values are categorical.\n",
    "\n",
    "### A Solution to The Column's Encoding Problem\n",
    "We can create Dummy variables/columns for the three countries.\n",
    "- Instead of having 1 column of the 3 countries, create 3 columns\n",
    "    - These 3 columns would indicate whether or not the country was present per cell based on the Country column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "a transformer to encode the Country column as dummy columns\n",
    "- remainder=passthrough guarantees that after fit_transforming the\n",
    "preprocess object, x contains all other variables (Age, Salary)\n",
    "and not just the transformed one (Country)\n",
    "\"\"\"\n",
    "dummy_transformer = make_column_transformer((OneHotEncoder(), [0]),\n",
    "                                            remainder=\"passthrough\")\n",
    "\"\"\"\n",
    "replace the Country column with 3 columns with values of 0 or 1\n",
    "- 0 indicates that country was not present in the cell\n",
    "- 1 indicates that country was present in the cell\n",
    "\"\"\"\n",
    "x = dummy_transformer.fit_transform(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "simply encode the Purchased column because the column's values\n",
    "are only \"Yes\" or \"No\", so it doesn't need dummy columns\n",
    "\"\"\"\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training and Testing Data Sets\n",
    "Let's split the customers data set into training and testing sets.\n",
    "\n",
    "Training data sets are used by the machine learning model to learn.  \n",
    "Testing data sets are used by the machine learning model to predict.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create x, y training and testing sets\n",
    "- x = independent variable\n",
    "- y = dependent variable\n",
    "- test_size = what percentage of data is for testing, 20% for our case\n",
    "- random_state = which state (seed) to split the data sets\n",
    "\"\"\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The x-training data set:\n",
      "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "\n",
      "The x-testing data set:\n",
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]]\n",
      "\n",
      "The y-training data set:\n",
      "[1 1 1 0 1 0 0 1]\n",
      "\n",
      "The y-testing data set:\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# print out the x training and testing data sets\n",
    "print(\"The x-training data set:\")\n",
    "print(x_train)\n",
    "print(\"\\nThe x-testing data set:\")\n",
    "print(x_test)\n",
    "\n",
    "# print out the y training and testing data sets\n",
    "print(\"\\nThe y-training data set:\")\n",
    "print(y_train)\n",
    "print(\"\\nThe y-testing data set:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "The columns are not within the same scale, which causes issues when comparing values in the machine learning models.\n",
    "\n",
    "For example, the \"Age\" column has values from 27 to 50. If we compare that to the \"Salary\" column, which has values from 52,000 to 83,000, then obviously the \"Salary\" column would dominate in value.\n",
    "\n",
    "### Why would these errors occur?\n",
    "Most ML models follow the Euclidian distance (distance formula).\n",
    "\n",
    "If a column has much wider range of values than another column, then the wider range of values would dominate the smaller range of values.\n",
    "\n",
    "### Solving The Scaling Problem\n",
    "We can solve this number scaling problem through 2 feature scaling methods.\n",
    "\n",
    "Either method you choose, the variables become in the same range and in the same scale, thus no variables dominate another variable when comparing them.\n",
    "\n",
    "#### Standarization\n",
    "```stand_value(x) = [x - mean(x)] / standard_deviation(x)```  \n",
    "\n",
    "Standardization rescales data to have a mean (μ) of 0 and standard deviation (σ) of 1 (unit variance)\n",
    "\n",
    "#### Normalization\n",
    "```norm_value(x) = [x - min(x)] / [max(x) - min(x)]```\n",
    "\n",
    "Normalization rescales the values into a range of [0,1]\n",
    "- This might be useful in some cases where all parameters need to have the same positive scale\n",
    "\n",
    "However, the outliers from the data set are lost.\n",
    "\n",
    "#### When Scaling This 2D Array Using Standarized Scaling:\n",
    "```python\n",
    "arr = [[1, 500, 1250],\n",
    "       [0, 750, 1000],\n",
    "       [0.5, 1000, 750]]\n",
    "```\n",
    "\n",
    "#### It Becomes:\n",
    "```python\n",
    "arr = [[ 1.22474487, -1.22474487,  1.22474487],\n",
    "       [-1.22474487,  0.        ,  0.        ],\n",
    "       [ 0.        ,  1.22474487, -1.22474487]]\n",
    "```\n",
    "\n",
    "As you can notice, the individual columns are all now on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a Standarization Scaler for Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# create a Standarization Scaler for the x sets\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# standarize the x-training set\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "\n",
    "\"\"\"\n",
    "standarize the x-testing set using the same scaler.\n",
    "\n",
    "we use the standarized scaling from the fitted training\n",
    "data set on the testing data set because it compares\n",
    "the testing data set values to the same mean, standard\n",
    "deviation, min, and max from the training data set.\n",
    "\n",
    "therefore, the feature scaling on the testing data set\n",
    "is the same as the feature scaling on the training data\n",
    "set because they were both fitted using the same scaler.\n",
    "\"\"\"\n",
    "x_test = sc_X.transform(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
