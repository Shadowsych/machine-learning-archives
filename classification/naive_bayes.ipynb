{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem\n",
    "In probability, Bayes theorem describes the probability an event based on prior knowledge may occur.\n",
    "\n",
    "### Bayes Theorem Formula\n",
    "<img src=\"images/nb/bayes_theorem.jpg\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "### Bayes Theorem Example\n",
    "Let's say there are two machines that produce wrenches.\n",
    "\n",
    "Machine 1 produces 30 wrenches per hour.  \n",
    "Machine 2 produces 20 wrenches per hour.\n",
    "\n",
    "Out of all the produced parts, 1% of the wrenches are defective parts.\n",
    "\n",
    "Out of all the defective parts, 50% came from Machine 1 and the other 50% came from Machine 2.\n",
    "\n",
    "Question: What is the probability that a part produced by Machine 2 is defective?\n",
    "\n",
    "### Bayes Theorem Example Solution\n",
    "Probability a part is from Machine 1: ```P(Mach1) = 30 / 50 = 0.6 = 60%```  \n",
    "Probability a part is from Machine 2: ```P(Mach2) =  20 / 50 = 0.4 = 40%```\n",
    "\n",
    "(Given) Probability a part is defective: ```P(Defect) = 1%```\n",
    "\n",
    "(Given) Likelihood a defective part is from Machine 1: ```P(Mach1 | Defect) = 50%```  \n",
    "(Given) Likelihood a defective part is from Machine 2: ```P(Mach2 | Defect) = 50%```\n",
    "- Notice how Machine 2 is only producing 40% of the outputs, yet 50% of defective parts are from Machine 2; therefore, we can observe Machine 2 produces more defective parts than Machine 1\n",
    "\n",
    "#### Now let's calculate the probability using Bayes Theorem:\n",
    "```P(Defect | Mach2)``` = ```P(Mach2 | Defect) * P(Defect) / P(Mach2)``` = ```0.0125 = 1.25%```\n",
    "\n",
    "Intuitively, we just counted the number of defective wrenches that came from Machine 2 and divided by the total number of wrenches that came from Machine 2.\n",
    "- This intuition is actually how Bayes Theorem works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "We can use the Naive Bayes theorem to calculate the probability that a data point is classified to a  category.\n",
    "\n",
    "# Naive Bayes Classifier Example\n",
    "Using two features, Age and Salary, determine if a person Drive or Walk.\n",
    "\n",
    "Is a \"New data point\" classified as a person that Walks or Drives?\n",
    "<img src=\"images/nb/naive_bayes_example.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "Let's assume, X = features (independent variables) of the \"New data point\":\n",
    "- Age = 30,000, Salary = 25\n",
    "\n",
    "### Solving Problem Using Bayes Theorem\n",
    "#### 1. Calculate the probability that the person walks:  \n",
    "<img src=\"images/nb/walks_bayes_theorem.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "P(Walks) = ```Number of Walkers / Total Observations``` = ```10 / 30```\n",
    "\n",
    "#### We can solve for P(X) using the \"radius\" method:\n",
    "<img src=\"images/nb/calculate_p(x).png\" height=\"75%\" width=\"75%\"></img>\n",
    "- Specify a radius hyperparameter, so the data points that lie within the radius are called the \"Similar Observations\"\n",
    "\n",
    "P(X) = ```4 / 30```\n",
    "\n",
    "P(X | Walks) = ```Number of Similar Observations Who Walk / Total Number of Walkers``` = ```3 / 10```\n",
    "\n",
    "#### Now substitute these variables into the Bayes Theorem:\n",
    "P(Walks | X) = ```(3 / 10 * 10 / 30) / (4 / 30)``` = ```0.75 = 75%```\n",
    "\n",
    "#### 2. Calculate the probability that the person drives:  \n",
    "<img src=\"images/nb/drives_bayes_theorem.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "In order to reduce redundancy, we can just use the same intuition from calculating the probability that the person walks. Therefore, the probability that the person drives is ```25%```.\n",
    "\n",
    "### 3. Conclusion\n",
    "Therefore, because 75% > 25%, we can classify the \"New data point\" as a person that walks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras About Naive Bayes Classifier\n",
    "### 1. Why is it called \"Naive\"?\n",
    "Because the Bayes Theorem requires \"independence assumptions.\" Therefore, the ML Model would require these assumptions, which are often times not correct. It's kind of naive to assume they're correct.\n",
    "\n",
    "For example, in the above example, we MUST assume that Age and Salary are independent.\n",
    "- We cannot have a correlation between Age and Salary, yet we kind of do in this problem because as a person's age increases then their salary increases\n",
    "\n",
    "\n",
    "### 2. What is P(X)?\n",
    "P(X) is the probability that a point from the entire data set has similar features to the \"New data point\". We define a radius to determine how many points would be similar to the \"New data point.\"\n",
    "\n",
    "### 3. How to handle more than 2 classes (classifications)?\n",
    "We would calculate the probability for all those classes, and the greatest probability is the classification.\n",
    "\n",
    "For example for an X \"New data point\", and there are 3 classes:\n",
    "- P(Study | X) = 25%\n",
    "- P(Games | X) = 40%\n",
    "- P(Talks | X) = 35%\n",
    "\n",
    "The person would be classified as someone who Games because it has the greatest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data set\n",
    "ads_df = pd.read_csv(\"datasets/social_network_ads.csv\")\n",
    "\n",
    "ads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the Age and Estimated Salary columns\n",
    "x = ads_df.iloc[:, [2, 3]].values\n",
    "\n",
    "# y is the Purchased column\n",
    "y = ads_df.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into training and testing data sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/pravat/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# import a Standarization Scaler for Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# feature scale the training and testing sets\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the gaussian naive bayes class\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "create a naive bayes classifier, then fit to the training set\n",
    "- the model automatically selects an optimal radius for the model\n",
    "\"\"\"\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the training set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the confusion matrix function\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65,  3],\n",
       "       [ 7, 25]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a confusion matrix that compares the y_test (actual) to the y_pred (prediction)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\"\"\"\n",
    "Read the Confusion Matrix diagonally:\n",
    "65 + 25 = 90 correct predictions\n",
    "7 + 3 = 10 incorrect predictions\n",
    "\"\"\"\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
