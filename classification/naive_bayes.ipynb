{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem\n",
    "In probability, Bayes theorem describes the probability an event based on prior knowledge may occur.\n",
    "\n",
    "### Bayes Theorem Formula\n",
    "<img src=\"images/nb/bayes_theorem.jpg\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "### Bayes Theorem Example\n",
    "Let's say there are two machines that produce wrenches.\n",
    "\n",
    "Machine 1 produces 30 wrenches per hour.  \n",
    "Machine 2 produces 20 wrenches per hour.\n",
    "\n",
    "Out of all the produced parts, 1% of the wrenches are defective parts.\n",
    "\n",
    "Out of all the defective parts, 50% came from Machine 1 and the other 50% came from Machine 2.\n",
    "\n",
    "Question: What is the probability that a part produced by Machine 2 is defective?\n",
    "\n",
    "### Bayes Theorem Example Solution\n",
    "Probability a part is from Machine 1: ```P(Mach1) = 30 / 50 = 0.6 = 60%```  \n",
    "Probability a part is from Machine 2: ```P(Mach2) =  20 / 50 = 0.4 = 40%```\n",
    "\n",
    "(Given) Probability a part is defective: ```P(Defect) = 1%```\n",
    "\n",
    "(Given) Likelihood a defective part is from Machine 1: ```P(Mach1 | Defect) = 50%```  \n",
    "(Given) Likelihood a defective part is from Machine 2: ```P(Mach2 | Defect) = 50%```\n",
    "- Notice how Machine 2 is only producing 40% of the outputs, yet 50% of defective parts are from Machine 2; therefore, we can observe Machine 2 produces more defective parts than Machine 1\n",
    "\n",
    "#### Now let's calculate the probability using Bayes Theorem:\n",
    "```P(Defect | Mach2)``` = ```P(Mach2 | Defect) * P(Defect) / P(Mach2)``` = ```0.0125 = 1.25%```\n",
    "\n",
    "Intuitively, we just counted the number of defective wrenches that came from Machine 2 and divided by the total number of wrenches that came from Machine 2.\n",
    "- This intuition is actually how Bayes Theorem works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "We can use the Naive Bayes theorem to calculate the probability that a data point is classified to a  category.\n",
    "\n",
    "# Naive Bayes Classifier Example\n",
    "Using two features, Age and Salary, determine if a person Drive or Walk.\n",
    "\n",
    "Is a \"New data point\" classified as a person that Walks or Drives?\n",
    "<img src=\"images/nb/naive_bayes_example.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "Let's assume, X = features (independent variables) of the \"New data point\":\n",
    "- Age = 30,000, Salary = 25\n",
    "\n",
    "### Solving Problem Using Bayes Theorem\n",
    "#### 1. Calculate the probability that the person walks:  \n",
    "<img src=\"images/nb/walks_bayes_theorem.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "P(Walks) = ```Number of Walkers / Total Observations``` = ```10 / 30```\n",
    "\n",
    "#### We can solve for P(X) using the \"radius\" method:\n",
    "<img src=\"images/nb/calculate_p(x).png\" height=\"75%\" width=\"75%\"></img>\n",
    "- Specify a radius hyperparameter, so the data points that lie within the radius are called the \"Similar Observations\"\n",
    "\n",
    "P(X) = ```4 / 30```\n",
    "\n",
    "P(X | Walks) = ```Number of Similar Observations Who Walk / Total Number of Walkers``` = ```3 / 10```\n",
    "\n",
    "#### Now substitute these variables into the Bayes Theorem:\n",
    "P(Walks | X) = ```(3 / 10 * 10 / 30) / (4 / 30)``` = ```0.75 = 75%```\n",
    "\n",
    "#### 2. Calculate the probability that the person drives:  \n",
    "<img src=\"images/nb/drives_bayes_theorem.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "In order to reduce redundancy, we can just use the same intuition from calculating the probability that the person walks. Therefore, the probability that the person drives is ```25%```.\n",
    "\n",
    "### 3. Conclusion\n",
    "Therefore, because 75% > 25%, we can classify the \"New data point\" as a person that walks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras About Naive Bayes Classifier\n",
    "### 1. Why is it called \"Naive\"?\n",
    "Because the Bayes Theorem requires \"independence assumptions.\" Therefore, the ML Model would require these assumptions, which are often times not correct. It's kind of naive to assume they're correct.\n",
    "\n",
    "For example, in the above example, we MUST assume that Age and Salary are independent.\n",
    "- We cannot have a correlation between Age and Salary, yet we kind of do in this problem because as a person's age increases then their salary increases\n",
    "\n",
    "\n",
    "### 2. What is P(X)?\n",
    "P(X) is the probability that a point from the entire data set has similar features to the \"New data point\". We define a radius to determine how many points would be similar to the \"New data point.\"\n",
    "\n",
    "### 3. How to handle more than 2 classes (classifications)?\n",
    "We would calculate the probability for all those classes, and the greatest probability is the classification.\n",
    "\n",
    "For example for an X \"New data point\", and there are 3 classes:\n",
    "- P(Study | X) = 25%\n",
    "- P(Games | X) = 40%\n",
    "- P(Talks | X) = 35%\n",
    "\n",
    "The person would be classified as someone who Games because it has the greatest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
